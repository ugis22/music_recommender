{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music recommender system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most used machine learning algorithms is recommendation systems. A **recommender** (or recommendation) **system** (or engine) is a filtering system which aim is to predict a rating or preference a user would give to an item, eg. a film, a product, a song, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which type of recommender can we have?   \n",
    "\n",
    "There are two main types of recommender systems:Â \n",
    "- Content-based filters\n",
    "- Collaborative filters\n",
    "  \n",
    "Content-based filters predicts what a user likes based on what that particular user has liked in the past. On the other hand, collaborative-based filters predict what a user like based on what other users, that are similar to that particular user, have liked. Among collaborative-based systems, we can encounter two types: **user-item** filtering and **item-item** filtering. \n",
    "  \n",
    "We'll go through the steps for generating a **item-item filtering** music recommender system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll import all the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the **[Million Song Dataset](http://millionsongdataset.com/)**, a freely-available collection of audio features and metadata for a million contemporary popular music tracks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two files that will be interesting for us. The first of them will give us information about the songs. Particularly, it contains the user ID, song ID and the listen count. On the other hand, the second file will contain song ID, title of that song, release, artist name and year. \n",
    "We need to merge these two DataFrames. For that aim, we'll use the `song_ID` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read userid-songid-listen_count\n",
    "song_info = pd.read_csv('https://static.turi.com/datasets/millionsong/10000.txt',sep='\\t',header=None)\n",
    "song_info.columns = ['user_id', 'song_id', 'listen_count']\n",
    "\n",
    "#Read song  metadata\n",
    "song_actual =  pd.read_csv('https://static.turi.com/datasets/millionsong/song_data.csv')\n",
    "song_actual.drop_duplicates(['song_id'], inplace=True)\n",
    "\n",
    "#Merge the two dataframes above to create input dataframe for recommender systems\n",
    "songs = pd.merge(song_info, song_actual, on=\"song_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = songs[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.to_csv('songs.cvs', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, any data science or machine learning project starts with an exploratory data analysis (EDA). The aim of EDA is to understand and get insights on our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first inspect the first rows of our `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Explore first rows\n",
    "songs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll check how many observions there are in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get total observations\n",
    "print(f\"There are {songs.shape[0]} observations in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we should perform some cleaning steps. But looking at the dataset, we can see that there is no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And most of the columns contain strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start exploring some characteristics of the dataset: \n",
    "\n",
    "- Unique songs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique songs\n",
    "print(f\"There are {songs['title'].unique().shape[0]} unique songs in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unique artists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique artists\n",
    "print(f\"There are {songs['artist_name'].unique().shape[0]} unique artists in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unique users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique users\n",
    "print(f\"There are {songs['user_id'].unique().shape[0]} unique songs in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll go ahead and explore the popularity of songs and artists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most popular songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we determine which are the most popular songs? For this task, we'll count how many times each song appears. Note that while we are using  `listen_count`, we only care about the number of rows, we don't consider the number present in that row. This number represents how many times one user listen to the same song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#count how many rows we have by song, we show only the ten more popular songs \n",
    "ten_pop_songs = songs.groupby('title')['listen_count'].count().reset_index().sort_values(['listen_count', 'title'], ascending = [0,1])\n",
    "ten_pop_songs['percentage']  = round(ten_pop_songs['listen_count'].div(ten_pop_songs['listen_count'].sum())*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_pop_songs = ten_pop_songs[:10]\n",
    "ten_pop_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ten_pop_songs['title'].tolist()\n",
    "counts = ten_pop_songs['listen_count'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.barplot(x=counts, y=labels, palette='Set3')\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most popular artist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next task, we'll count how many times each artist appears. Again, we'll count how many times the same artist appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count how many rows we have by artist name, we show only the ten more popular artist \n",
    "ten_pop_artists  = songs.groupby(['artist_name'])['listen_count'].count().reset_index().sort_values(['listen_count', 'artist_name'], \n",
    "                                                                                                ascending = [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_pop_artists = ten_pop_artists[:10]\n",
    "ten_pop_artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "labels = ten_pop_artists['artist_name'].tolist()\n",
    "counts = ten_pop_artists['listen_count'].tolist()\n",
    "sns.barplot(x=counts, y=labels, palette='Set2')\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listen count by user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get some other information from the feature `listen_count`. We will answer the folloging questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many times on average the same user listen to a same song?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"On average, a user listen to the same song {songs['listen_count'].mean()} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the distribution of `listen_count`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "sns.boxplot(x='listen_count', data=songs)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What was the maximum times the same user listen to a same song?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The maximum times the same user listened to the same songs was as follows:\")\n",
    "songs.sort_values('listen_count', ascending=False)[['title',  'listen_count']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we know that we want to predict songs. So, in order to have all the information in only one column, we'll concatenate the song `title` with the `artist_name`. We'll assign the resultant string to the new column `song`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate title and artist name. Assign it to new columns\n",
    "songs['song'] = songs['title'] + \"-\" + songs[\"artist_name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we need to define the recommerders. For this aim, we will first build a class called `item_similarity_recommender`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class for Item similarity based Recommender System model\n",
    "class item_similarity_recommender():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.train_data = None\n",
    "        self.user_id = None\n",
    "        self.item_id = None\n",
    "        self.cooccurence_matrix = None\n",
    "        self.songs_dict = None\n",
    "        self.rev_songs_dict = None\n",
    "        self.item_similarity_recommendations = None\n",
    "        \n",
    "    #Get unique items corresponding to a given user\n",
    "    def get_user_items(self, user):\n",
    "        user_data = self.train_data[self.train_data[self.user_id] == user]\n",
    "        user_items = list(user_data[self.item_id].unique()) \n",
    "        return user_items\n",
    "        \n",
    "    #Get unique users for a given item\n",
    "    def get_item_users(self, item):\n",
    "        item_data = self.train_data[self.train_data[self.item_id] == item]\n",
    "        item_users = set(item_data[self.user_id].unique())\n",
    "        return item_users\n",
    "        \n",
    "    #Get unique items in the training data\n",
    "    def get_all_items_train_data(self):\n",
    "        all_items = list(self.train_data[self.item_id].unique())\n",
    "        return all_items\n",
    "        \n",
    "    #Construct cooccurence matrix\n",
    "    def construct_cooccurence_matrix(self, user_songs, all_songs):\n",
    "        #Get users for all songs in user_songs.\n",
    "        user_songs_users = []        \n",
    "        for i in range(0, len(user_songs)):\n",
    "            user_songs_users.append(self.get_item_users(user_songs[i]))\n",
    "\n",
    "        cooccurence_matrix = np.matrix(np.zeros(shape=(len(user_songs), len(all_songs))), float)\n",
    "\n",
    "        for i in range(0,len(all_songs)):\n",
    "            #Calculate unique listeners (users) of song (item) i\n",
    "            songs_i_data = self.train_data[self.train_data[self.item_id] == all_songs[i]]\n",
    "            users_i = set(songs_i_data[self.user_id].unique())\n",
    "            \n",
    "            for j in range(0,len(user_songs)):       \n",
    "                    \n",
    "                #Get unique listeners (users) of song (item) j\n",
    "                users_j = user_songs_users[j]\n",
    "                    \n",
    "                #Calculate intersection of listeners of songs i and j\n",
    "                users_intersection = users_i.intersection(users_j)\n",
    "                \n",
    "                #Calculate cooccurence_matrix[i,j] as Jaccard Index\n",
    "                if len(users_intersection) != 0:\n",
    "                    #Calculate union of listeners of songs i and j\n",
    "                    users_union = users_i.union(users_j)\n",
    "                    \n",
    "                    cooccurence_matrix[j,i] = float(len(users_intersection))/float(len(users_union))\n",
    "                else:\n",
    "                    cooccurence_matrix[j,i] = 0\n",
    "                    \n",
    "        \n",
    "        return cooccurence_matrix\n",
    "\n",
    "    \n",
    "    #Use the cooccurence matrix to make top recommendations\n",
    "    def generate_top_recommendations(self, user, cooccurence_matrix, all_songs, user_songs):\n",
    "        print(\"Non zero values in cooccurence_matrix :%d\" % np.count_nonzero(cooccurence_matrix))\n",
    "        \n",
    "        #Calculate a weighted average of the scores in cooccurence matrix for all user songs.\n",
    "        user_sim_scores = cooccurence_matrix.sum(axis=0)/float(cooccurence_matrix.shape[0])\n",
    "        user_sim_scores = np.array(user_sim_scores)[0].tolist()\n",
    " \n",
    "        #Sort the indices of user_sim_scores based upon their value\n",
    "        #Also maintain the corresponding score\n",
    "        sort_index = sorted(((e,i) for i,e in enumerate(list(user_sim_scores))), reverse=True)\n",
    "    \n",
    "        #Create a dataframe from the following\n",
    "        columns = ['user_id', 'song', 'score', 'rank']\n",
    "        #index = np.arange(1) # array of numbers for the number of samples\n",
    "        df = pd.DataFrame(columns=columns)\n",
    "         \n",
    "        #Fill the dataframe with top 10 item based recommendations\n",
    "        rank = 1 \n",
    "        for i in range(0,len(sort_index)):\n",
    "            if ~np.isnan(sort_index[i][0]) and all_songs[sort_index[i][1]] not in user_songs and rank <= 10:\n",
    "                df.loc[len(df)]=[user,all_songs[sort_index[i][1]],sort_index[i][0],rank]\n",
    "                rank = rank+1\n",
    "        \n",
    "        #Handle the case where there are no recommendations\n",
    "        if df.shape[0] == 0:\n",
    "            print(\"The current user has no songs for training the item similarity based recommendation model.\")\n",
    "            return -1\n",
    "        else:\n",
    "            return df\n",
    " \n",
    "    #Create the item similarity based recommender system model\n",
    "    def create(self, train_data, user_id, item_id):\n",
    "        self.train_data = train_data\n",
    "        self.user_id = user_id\n",
    "        self.item_id = item_id\n",
    "\n",
    "    #Use the item similarity based recommender system model to\n",
    "    #make recommendations\n",
    "    def recommend(self, user):\n",
    "        \n",
    "        user_songs = self.get_user_items(user)    \n",
    "            \n",
    "        print(\"No. of unique songs for the user: %d\" % len(user_songs))\n",
    "        \n",
    "        all_songs = self.get_all_items_train_data()\n",
    "        \n",
    "        print(\"no. of unique songs in the training set: %d\" % len(all_songs))\n",
    "         \n",
    "        cooccurence_matrix = self.construct_cooccurence_matrix(user_songs, all_songs)\n",
    "        \n",
    "        df_recommendations = self.generate_top_recommendations(user, cooccurence_matrix, all_songs, user_songs)\n",
    "                \n",
    "        return df_recommendations\n",
    "    \n",
    "    #Get similar items to given items\n",
    "    def get_similar_items(self, item_list):\n",
    "        \n",
    "        user_songs = item_list\n",
    "        \n",
    "        all_songs = self.get_all_items_train_data()\n",
    "        \n",
    "        print(\"no. of unique songs in the training set: %d\" % len(all_songs))\n",
    "         \n",
    "        cooccurence_matrix = self.construct_cooccurence_matrix(user_songs, all_songs)\n",
    "\n",
    "        user = \"\"\n",
    "        df_recommendations = self.generate_top_recommendations(user, cooccurence_matrix, all_songs, user_songs)\n",
    "         \n",
    "        return df_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(songs, test_size = 0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_model = item_similarity_recommender()\n",
    "is_model.create(train_data, 'user_id', 'song')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = songs['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = users[5]\n",
    "user_items = is_model.get_user_items(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_item in user_items:\n",
    "    print(user_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_model.recommend(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_model.get_similar_items(['U Smile - Justin Bieber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song = 'Yellow - Coldplay'\n",
    "is_model.get_similar_items([song])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
